{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class 1: Burger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR ='C:\\Yelp\\Train'\n",
    "\n",
    "# Want to know how we should format the height x width image data dimensions\n",
    "# for inputting to a keras model\n",
    "def get_size_statistics():\n",
    "    heights = []\n",
    "    widths = []\n",
    "    img_count = 0\n",
    "    for img in os.listdir(DIR):\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            data = np.array(Image.open(path))\n",
    "            heights.append(data.shape[0])\n",
    "            widths.append(data.shape[1])\n",
    "            img_count += 1\n",
    "    avg_height = sum(heights) / len(heights)\n",
    "    avg_width = sum(widths) / len(widths)\n",
    "    print(\"Average Height: \" + str(avg_height))\n",
    "    print(\"Max Height: \" + str(max(heights)))\n",
    "    print(\"Min Height: \" + str(min(heights)))\n",
    "    print('\\n')\n",
    "    print(\"Average Width: \" + str(avg_width))\n",
    "    print(\"Max Width: \" + str(max(widths)))\n",
    "    print(\"Min Width: \" + str(min(widths)))\n",
    "get_size_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name):\n",
    "    word_label = name.split('(')[0]\n",
    "    #print(word_label)\n",
    "    if word_label == 'Burger ':  return 0\n",
    "    elif word_label == 'pizza ': return 1\n",
    "    elif word_label == 'Chicken ': return 1\n",
    "    elif word_label == 'Sweet ': return 1\n",
    "    elif word_label == 'Tacos ': return 1\n",
    "    elif word_label == 'Drink ': return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def load_training_data():\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            X_train=np.array(img)\n",
    "            Y_train=label\n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(load_training_data())\n",
    "y=len(train_data)\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y-1):\n",
    "    img=np.array((train_data[i][0]).reshape(256,256))\n",
    "    X.append(img)\n",
    "    label=np.array(train_data[i][1])\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 256, 256)\n",
      "(72, 256, 256)\n",
      "(286,)\n",
      "(72,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(256, 256,..., activation=\"relu\")`\n",
      "  \n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Conv2D(64,3,3,input_shape=(256,256,1),activation='relu'))\n",
    "classifier.add(Conv2D(32,3,3,activation='relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim=2,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(286,256,256,1)\n",
    "X_test = X_test.reshape(72,256,256,1)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 254, 254, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 252, 252, 32)      18464     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2032128)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 4064258   \n",
      "=================================================================\n",
      "Total params: 4,083,362\n",
      "Trainable params: 4,083,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 286 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "286/286 [==============================] - 62s 215ms/step - loss: 0.7803 - acc: 0.2762 - val_loss: 0.6931 - val_acc: 0.3056\n",
      "Epoch 2/3\n",
      "286/286 [==============================] - 63s 220ms/step - loss: 0.6931 - acc: 0.2692 - val_loss: 0.6931 - val_acc: 0.3056\n",
      "Epoch 3/3\n",
      "286/286 [==============================] - 65s 226ms/step - loss: 0.6931 - acc: 0.2692 - val_loss: 0.6931 - val_acc: 0.3056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21412e2a550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 7s 90ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931471824645996, 0.3055555555555556]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 127, 127, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 62, 62, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 60, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 96)          384       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 64)          55360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 396,386\n",
      "Trainable params: 395,490\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "286/286 [==============================] - 50s 176ms/step - loss: 0.0945 - acc: 0.9685\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 43s 152ms/step - loss: 0.1026 - acc: 0.9650\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 42s 147ms/step - loss: 0.1086 - acc: 0.9615\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 41s 142ms/step - loss: 0.1299 - acc: 0.9545\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 41s 143ms/step - loss: 0.1096 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 41s 142ms/step - loss: 0.0799 - acc: 0.9860\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 41s 143ms/step - loss: 0.0262 - acc: 0.9930\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 43s 151ms/step - loss: 0.0349 - acc: 0.9895\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 44s 152ms/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 46s 161ms/step - loss: 0.0300 - acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21429dbb1d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10, validation_steps=None,verbose = 1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0643285711606343, 0.7222222222222222]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.22222222222221\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.64508820e-05, 9.38421607e-01],\n",
       "       [3.14071774e-03, 4.70596850e-02],\n",
       "       [6.37763500e-01, 1.24543905e-04],\n",
       "       [2.87970364e-01, 1.63912773e-04],\n",
       "       [6.59001350e-01, 1.60634518e-04],\n",
       "       [3.48001719e-04, 3.95758152e-01],\n",
       "       [2.16012597e-02, 1.99959546e-01],\n",
       "       [2.57045031e-04, 6.19734347e-01],\n",
       "       [4.58657742e-05, 7.04783440e-01],\n",
       "       [2.68220901e-07, 9.70463455e-01],\n",
       "       [2.30112672e-03, 4.58062410e-01],\n",
       "       [1.98676288e-02, 4.15462554e-02],\n",
       "       [1.76241994e-03, 1.47605985e-01],\n",
       "       [1.06828660e-01, 1.51693821e-04],\n",
       "       [9.05409455e-03, 2.51138210e-02],\n",
       "       [1.22898817e-03, 1.74040258e-01],\n",
       "       [7.65944123e-02, 3.57246399e-03],\n",
       "       [1.58919245e-01, 1.07288361e-05],\n",
       "       [1.76185369e-03, 2.99904943e-01],\n",
       "       [1.07698143e-02, 5.65637648e-02],\n",
       "       [1.04010105e-05, 9.30260658e-01],\n",
       "       [4.83691692e-05, 7.85287499e-01],\n",
       "       [1.78763270e-03, 4.67881292e-01],\n",
       "       [5.45272231e-03, 5.35265088e-01],\n",
       "       [1.56199276e-01, 1.20601058e-03],\n",
       "       [7.81327486e-04, 3.29512000e-01],\n",
       "       [1.52413249e-02, 5.48331141e-02],\n",
       "       [4.30741906e-03, 2.29703605e-01],\n",
       "       [3.85683656e-01, 1.92543864e-03],\n",
       "       [3.23161483e-03, 1.47494376e-01],\n",
       "       [2.07281619e-01, 3.03420424e-03],\n",
       "       [2.71936268e-01, 6.92486763e-04],\n",
       "       [2.56285965e-02, 7.21475780e-02],\n",
       "       [8.98181558e-01, 3.57627869e-07],\n",
       "       [5.98246157e-02, 5.42032719e-03],\n",
       "       [2.38418579e-07, 7.22103715e-01],\n",
       "       [9.06634629e-02, 5.73208928e-03],\n",
       "       [8.28504562e-05, 7.62257338e-01],\n",
       "       [1.40866637e-03, 3.11331272e-01],\n",
       "       [3.25231403e-01, 2.18191743e-03],\n",
       "       [7.31069744e-02, 5.50940633e-03],\n",
       "       [2.58299708e-03, 3.49927247e-02],\n",
       "       [4.44382429e-04, 3.61539543e-01],\n",
       "       [4.02225852e-02, 3.31857800e-03],\n",
       "       [1.68189734e-01, 6.14240766e-03],\n",
       "       [1.69633776e-01, 4.18029726e-02],\n",
       "       [2.35658884e-03, 1.59633160e-03],\n",
       "       [5.99491000e-02, 9.80669260e-03],\n",
       "       [5.06019592e-03, 3.55627656e-01],\n",
       "       [9.05081630e-03, 5.57674468e-02],\n",
       "       [1.88175738e-02, 3.59539390e-02],\n",
       "       [1.46924257e-01, 1.09997690e-02],\n",
       "       [5.68181276e-04, 4.33501095e-01],\n",
       "       [4.30778563e-02, 2.21756399e-02],\n",
       "       [5.33765554e-03, 2.21817344e-01],\n",
       "       [1.23269886e-01, 2.10474730e-02],\n",
       "       [1.18032098e-03, 1.38871282e-01],\n",
       "       [7.91421533e-03, 1.87657982e-01],\n",
       "       [2.10669637e-03, 7.97085047e-01],\n",
       "       [8.68168473e-03, 2.91179955e-01],\n",
       "       [4.35601056e-01, 9.76324081e-04],\n",
       "       [2.41442621e-02, 1.42192751e-01],\n",
       "       [3.90741229e-03, 2.34807342e-01],\n",
       "       [1.01220608e-03, 5.20507455e-01],\n",
       "       [6.47834241e-02, 2.22894549e-02],\n",
       "       [3.49216104e-01, 3.09616327e-04],\n",
       "       [9.29743052e-04, 7.01418817e-01],\n",
       "       [2.29477882e-05, 8.49879384e-01],\n",
       "       [1.65849924e-04, 7.89646208e-01],\n",
       "       [9.28819180e-04, 1.97447240e-01],\n",
       "       [5.00674844e-02, 7.64843822e-02],\n",
       "       [5.98863959e-02, 1.13858074e-01]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(predictions[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==predictions[i][j]):\n",
    "            result=j+1\n",
    "            Pred_Max_Positions.append(j)\n",
    "#Pred_Max_Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(y_test[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==y_test[i][j]):\n",
    "            result=j\n",
    "            Test_Max_Positions.append(j)\n",
    "#Test_Max_Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  8],\n",
       "       [12, 38]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "CM_CNN_1=confusion_matrix(Test_Max_Positions,Pred_Max_Positions)\n",
    "CM_CNN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.64      0.58        22\n",
      "           1       0.83      0.76      0.79        50\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        72\n",
      "   macro avg       0.68      0.70      0.69        72\n",
      "weighted avg       0.74      0.72      0.73        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Test_Max_Positions,Pred_Max_Positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class 2: Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Height: 383.958217270195\n",
      "Max Height: 400\n",
      "Min Height: 150\n",
      "\n",
      "\n",
      "Average Width: 482.1309192200557\n",
      "Max Width: 600\n",
      "Min Width: 200\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR = 'D:\\SEM II\\DSP\\Project\\Image Dataset\\Train'\n",
    "\n",
    "# Want to know how we should format the height x width image data dimensions\n",
    "# for inputting to a keras model\n",
    "def get_size_statistics():\n",
    "    heights = []\n",
    "    widths = []\n",
    "    img_count = 0\n",
    "    for img in os.listdir(DIR):\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            data = np.array(Image.open(path))\n",
    "            heights.append(data.shape[0])\n",
    "            widths.append(data.shape[1])\n",
    "            img_count += 1\n",
    "    avg_height = sum(heights) / len(heights)\n",
    "    avg_width = sum(widths) / len(widths)\n",
    "    print(\"Average Height: \" + str(avg_height))\n",
    "    print(\"Max Height: \" + str(max(heights)))\n",
    "    print(\"Min Height: \" + str(min(heights)))\n",
    "    print('\\n')\n",
    "    print(\"Average Width: \" + str(avg_width))\n",
    "    print(\"Max Width: \" + str(max(widths)))\n",
    "    print(\"Min Width: \" + str(min(widths)))\n",
    "get_size_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name):\n",
    "    word_label = name.split('(')[0]\n",
    "    #print(word_label)\n",
    "    if word_label == 'Burger ':  return 1\n",
    "    elif word_label == 'pizza ': return 0\n",
    "    elif word_label == 'Chicken ': return 1\n",
    "    elif word_label == 'Sweet ': return 1\n",
    "    elif word_label == 'Tacos ': return 1\n",
    "    elif word_label == 'Drink ': return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def load_training_data():\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            X_train=np.array(img)\n",
    "            Y_train=label\n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(load_training_data())\n",
    "y=len(train_data)\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y-1):\n",
    "    img=np.array((train_data[i][0]).reshape(256,256))\n",
    "    X.append(img)\n",
    "    label=np.array(train_data[i][1])\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(256, 256,..., activation=\"relu\")`\n",
      "  \n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Conv2D(64,3,3,input_shape=(256,256,1),activation='relu'))\n",
    "classifier.add(Conv2D(32,3,3,activation='relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim=2,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(286,256,256,1)\n",
    "X_test = X_test.reshape(72,256,256,1)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 254, 254, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 252, 252, 32)      18464     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2032128)           0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 4064258   \n",
      "=================================================================\n",
      "Total params: 4,083,362\n",
      "Trainable params: 4,083,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 286 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "286/286 [==============================] - 62s 216ms/step - loss: 10.7019 - acc: 0.3287 - val_loss: 11.4170 - val_acc: 0.2917\n",
      "Epoch 2/3\n",
      "286/286 [==============================] - 64s 224ms/step - loss: 11.7223 - acc: 0.2727 - val_loss: 11.4170 - val_acc: 0.2917\n",
      "Epoch 3/3\n",
      "286/286 [==============================] - 66s 229ms/step - loss: 11.7223 - acc: 0.2727 - val_loss: 11.4170 - val_acc: 0.2917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21430230e10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 127, 127, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 62, 62, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 60, 60, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 30, 30, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 12, 12, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 6, 6, 96)          384       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 64)          55360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 396,386\n",
      "Trainable params: 395,490\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "286/286 [==============================] - 41s 142ms/step - loss: 0.5180 - acc: 0.7343\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 42s 147ms/step - loss: 0.3364 - acc: 0.8706\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 46s 160ms/step - loss: 0.1960 - acc: 0.9266\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 46s 160ms/step - loss: 0.1388 - acc: 0.9615\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 45s 156ms/step - loss: 0.0745 - acc: 0.9825\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 43s 150ms/step - loss: 0.0328 - acc: 0.9930\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 42s 147ms/step - loss: 0.0182 - acc: 0.9965\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 41s 144ms/step - loss: 0.0143 - acc: 0.9965\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 44s 155ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 48s 167ms/step - loss: 0.0179 - acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214179352e8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10, validation_steps=None,verbose = 1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38448719183603924, 0.9166666666666666]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.66666666666666\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        21\n",
      "           1       0.88      0.98      0.93        51\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        72\n",
      "   macro avg       0.91      0.82      0.85        72\n",
      "weighted avg       0.89      0.89      0.88        72\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14,  7],\n",
       "       [ 1, 50]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "Pred_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(predictions[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==predictions[i][j]):\n",
    "            result=j\n",
    "            Pred_Max_Positions.append(j)\n",
    "#Pred_Max_Positions\n",
    "\n",
    "Test_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(y_test[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==y_test[i][j]):\n",
    "            result=j\n",
    "            Test_Max_Positions.append(j)\n",
    "#Test_Max_Positions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Test_Max_Positions,Pred_Max_Positions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM_CNN_2=confusion_matrix(Test_Max_Positions,Pred_Max_Positions)\n",
    "CM_CNN_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chicken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name):\n",
    "    word_label = name.split('(')[0]\n",
    "    #print(word_label)\n",
    "    if word_label == 'Burger ':  return 1\n",
    "    elif word_label == 'pizza ': return 1\n",
    "    elif word_label == 'Chicken ': return 0\n",
    "    elif word_label == 'Sweet ': return 1\n",
    "    elif word_label == 'Tacos ': return 1\n",
    "    elif word_label == 'Drink ': return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def load_training_data():\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            X_train=np.array(img)\n",
    "            Y_train=label\n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(load_training_data())\n",
    "y=len(train_data)\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y-1):\n",
    "    img=np.array((train_data[i][0]).reshape(256,256))\n",
    "    X.append(img)\n",
    "    label=np.array(train_data[i][1])\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(256, 256,..., activation=\"relu\")`\n",
      "  \n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Conv2D(64,3,3,input_shape=(256,256,1),activation='relu'))\n",
    "classifier.add(Conv2D(32,3,3,activation='relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim=2,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(286,256,256,1)\n",
    "X_test = X_test.reshape(72,256,256,1)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 286 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 1.1929 - acc: 0.8706 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 2/3\n",
      "286/286 [==============================] - 60s 209ms/step - loss: 0.3945 - acc: 0.9755 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 3/3\n",
      "286/286 [==============================] - 68s 237ms/step - loss: 0.3945 - acc: 0.9755 - val_loss: 0.6716 - val_acc: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2142f44dda0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "286/286 [==============================] - 44s 153ms/step - loss: 0.3041 - acc: 0.8741\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 45s 157ms/step - loss: 0.1176 - acc: 0.9755\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 42s 149ms/step - loss: 0.0840 - acc: 0.9755\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 42s 146ms/step - loss: 0.0600 - acc: 0.9755\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 43s 152ms/step - loss: 0.0404 - acc: 0.9755\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 42s 147ms/step - loss: 0.0328 - acc: 0.9825\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 43s 152ms/step - loss: 0.0222 - acc: 0.9895\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 47s 163ms/step - loss: 0.0166 - acc: 0.9895\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 44s 153ms/step - loss: 0.0125 - acc: 0.9965\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 45s 159ms/step - loss: 0.0063 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2142fa65940>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10, validation_steps=None,verbose = 1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2533058675989095, 0.9583333333333334]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.83333333333334\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.96      1.00      0.98        69\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        72\n",
      "   macro avg       0.48      0.50      0.49        72\n",
      "weighted avg       0.92      0.96      0.94        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3],\n",
       "       [ 0, 69]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "Pred_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(predictions[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==predictions[i][j]):\n",
    "            result=j+1\n",
    "            Pred_Max_Positions.append(j)\n",
    "#Pred_Max_Positions\n",
    "\n",
    "Test_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(y_test[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==y_test[i][j]):\n",
    "            result=j\n",
    "            Test_Max_Positions.append(j)\n",
    "#Test_Max_Positions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Test_Max_Positions,Pred_Max_Positions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM_CNN_3=confusion_matrix(Test_Max_Positions,Pred_Max_Positions)\n",
    "CM_CNN_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name):\n",
    "    word_label = name.split('(')[0]\n",
    "    #print(word_label)\n",
    "    if word_label == 'Burger ':  return 1\n",
    "    elif word_label == 'pizza ': return 1\n",
    "    elif word_label == 'Chicken ': return 1\n",
    "    elif word_label == 'Sweet ': return 0\n",
    "    elif word_label == 'Tacos ': return 1\n",
    "    elif word_label == 'Drink ': return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def load_training_data():\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            X_train=np.array(img)\n",
    "            Y_train=label\n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(load_training_data())\n",
    "y=len(train_data)\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y-1):\n",
    "    img=np.array((train_data[i][0]).reshape(256,256))\n",
    "    X.append(img)\n",
    "    label=np.array(train_data[i][1])\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(256, 256,..., activation=\"relu\")`\n",
      "  \n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Conv2D(64,3,3,input_shape=(256,256,1),activation='relu'))\n",
    "classifier.add(Conv2D(32,3,3,activation='relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim=2,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(286,256,256,1)\n",
    "X_test = X_test.reshape(72,256,256,1)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 286 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "286/286 [==============================] - 83s 290ms/step - loss: nan - acc: 0.1154 - val_loss: nan - val_acc: 0.0972\n",
      "Epoch 2/3\n",
      "286/286 [==============================] - 75s 264ms/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.0972\n",
      "Epoch 3/3\n",
      "286/286 [==============================] - 71s 250ms/step - loss: nan - acc: 0.1119 - val_loss: nan - val_acc: 0.0972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21441015d68>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "286/286 [==============================] - 57s 199ms/step - loss: 0.4364 - acc: 0.8671\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 54s 189ms/step - loss: 0.3113 - acc: 0.8881\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 53s 185ms/step - loss: 0.2422 - acc: 0.8881\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 53s 187ms/step - loss: 0.1893 - acc: 0.8916\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 52s 182ms/step - loss: 0.1497 - acc: 0.8951\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 53s 187ms/step - loss: 0.1183 - acc: 0.9231\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 54s 187ms/step - loss: 0.1100 - acc: 0.9301\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 53s 186ms/step - loss: 0.0903 - acc: 0.9825\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 52s 184ms/step - loss: 0.0717 - acc: 0.9755\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 52s 183ms/step - loss: 0.0359 - acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214447041d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10, validation_steps=None,verbose = 1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 4s 54ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5978704214923911, 0.875]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.5\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.90      0.97      0.93        65\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        72\n",
      "   macro avg       0.45      0.48      0.47        72\n",
      "weighted avg       0.81      0.88      0.84        72\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  7],\n",
       "       [ 2, 63]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "Pred_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(predictions[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==predictions[i][j]):\n",
    "            result=j+1\n",
    "            Pred_Max_Positions.append(j)\n",
    "#Pred_Max_Positions\n",
    "\n",
    "Test_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(y_test[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==y_test[i][j]):\n",
    "            result=j\n",
    "            Test_Max_Positions.append(j)\n",
    "#Test_Max_Positions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Test_Max_Positions,Pred_Max_Positions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM_CNN_3=confusion_matrix(Test_Max_Positions,Pred_Max_Positions)\n",
    "CM_CNN_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tacos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name):\n",
    "    word_label = name.split('(')[0]\n",
    "    #print(word_label)\n",
    "    if word_label == 'Burger ':  return 1\n",
    "    elif word_label == 'pizza ': return 1\n",
    "    elif word_label == 'Chicken ': return 1\n",
    "    elif word_label == 'Sweet ': return 1\n",
    "    elif word_label == 'Tacos ': return 0\n",
    "    elif word_label == 'Drink ': return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def load_training_data():\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            X_train=np.array(img)\n",
    "            Y_train=label\n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(load_training_data())\n",
    "y=len(train_data)\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y-1):\n",
    "    img=np.array((train_data[i][0]).reshape(256,256))\n",
    "    X.append(img)\n",
    "    label=np.array(train_data[i][1])\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(256, 256,..., activation=\"relu\")`\n",
      "  \n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Conv2D(64,3,3,input_shape=(256,256,1),activation='relu'))\n",
    "classifier.add(Conv2D(32,3,3,activation='relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim=2,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(286,256,256,1)\n",
    "X_test = X_test.reshape(72,256,256,1)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 286 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "286/286 [==============================] - 79s 277ms/step - loss: 1.1517 - acc: 0.8741 - val_loss: 0.4477 - val_acc: 0.9722\n",
      "Epoch 2/3\n",
      "286/286 [==============================] - 80s 281ms/step - loss: 0.4509 - acc: 0.9720 - val_loss: 0.4477 - val_acc: 0.9722\n",
      "Epoch 3/3\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4509 - acc: 0.9720 - val_loss: 0.4477 - val_acc: 0.9722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21449f92390>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 6s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44772493839263916, 0.9722222222222222]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 127, 127, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 62, 62, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 60, 60, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 30, 30, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 30, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 28, 28, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 14, 14, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 12, 12, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 6, 6, 96)          384       \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 4, 4, 64)          55360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 396,386\n",
      "Trainable params: 395,490\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "286/286 [==============================] - 59s 207ms/step - loss: 0.2429 - acc: 0.9406\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 53s 187ms/step - loss: 0.1414 - acc: 0.9720\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 52s 181ms/step - loss: 0.0820 - acc: 0.9720\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 53s 187ms/step - loss: 0.0589 - acc: 0.9720\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 54s 189ms/step - loss: 0.0476 - acc: 0.9720\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 55s 191ms/step - loss: 0.0323 - acc: 0.9755\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 57s 198ms/step - loss: 0.0281 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 56s 198ms/step - loss: 0.0212 - acc: 0.9895\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 66s 229ms/step - loss: 0.0200 - acc: 0.9930\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 63s 221ms/step - loss: 0.0176 - acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21434fb1e48>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10, validation_steps=None,verbose = 1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 5s 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14849693711019224, 0.9722222222222222]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.22222222222221\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.97      1.00      0.99        70\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        72\n",
      "   macro avg       0.49      0.50      0.49        72\n",
      "weighted avg       0.95      0.97      0.96        72\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 0, 70]], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "Pred_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(predictions[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==predictions[i][j]):\n",
    "            result=j+1\n",
    "            Pred_Max_Positions.append(j)\n",
    "#Pred_Max_Positions\n",
    "\n",
    "Test_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(y_test[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==y_test[i][j]):\n",
    "            result=j\n",
    "            Test_Max_Positions.append(j)\n",
    "#Test_Max_Positions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Test_Max_Positions,Pred_Max_Positions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM_CNN_3=confusion_matrix(Test_Max_Positions,Pred_Max_Positions)\n",
    "CM_CNN_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name):\n",
    "    word_label = name.split('(')[0]\n",
    "    #print(word_label)\n",
    "    if word_label == 'Burger ':  return 1\n",
    "    elif word_label == 'pizza ': return 1\n",
    "    elif word_label == 'Chicken ': return 1\n",
    "    elif word_label == 'Sweet ': return 1\n",
    "    elif word_label == 'Tacos ': return 1\n",
    "    elif word_label == 'Drink ': return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def load_training_data():\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            X_train=np.array(img)\n",
    "            Y_train=label\n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(load_training_data())\n",
    "y=len(train_data)\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y-1):\n",
    "    img=np.array((train_data[i][0]).reshape(256,256))\n",
    "    X.append(img)\n",
    "    label=np.array(train_data[i][1])\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(256, 256,..., activation=\"relu\")`\n",
      "  \n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Conv2D(64,3,3,input_shape=(256,256,1),activation='relu'))\n",
    "classifier.add(Conv2D(32,3,3,activation='relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim=2,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(286,256,256,1)\n",
    "X_test = X_test.reshape(72,256,256,1)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 286 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "286/286 [==============================] - 100s 351ms/step - loss: 5.0143 - acc: 0.6888 - val_loss: 4.7011 - val_acc: 0.7083\n",
      "Epoch 2/3\n",
      "286/286 [==============================] - 92s 321ms/step - loss: 4.4522 - acc: 0.7238 - val_loss: 4.7011 - val_acc: 0.7083\n",
      "Epoch 3/3\n",
      "286/286 [==============================] - 95s 332ms/step - loss: 4.4522 - acc: 0.7238 - val_loss: 4.7011 - val_acc: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2144dc69ef0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 7s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.7011111577351885, 0.7083333333333334]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "286/286 [==============================] - 69s 242ms/step - loss: 0.5797 - acc: 0.6888\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 64s 223ms/step - loss: 0.3763 - acc: 0.8042\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 62s 218ms/step - loss: 0.2821 - acc: 0.8776\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 65s 226ms/step - loss: 0.2241 - acc: 0.8916\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 64s 224ms/step - loss: 0.1732 - acc: 0.9091\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 65s 228ms/step - loss: 0.1685 - acc: 0.9336\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 50s 177ms/step - loss: 0.0812 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 40s 139ms/step - loss: 0.0416 - acc: 0.9860\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 40s 141ms/step - loss: 0.0513 - acc: 0.9825\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 41s 142ms/step - loss: 0.0657 - acc: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2145766f198>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10, validation_steps=None,verbose = 1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7480051318804423, 0.8333333333333334]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        21\n",
      "           1       0.88      0.88      0.88        51\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        72\n",
      "   macro avg       0.80      0.80      0.80        72\n",
      "weighted avg       0.83      0.83      0.83        72\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15,  6],\n",
       "       [ 6, 45]], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "Pred_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(predictions[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==predictions[i][j]):\n",
    "            result=j+1\n",
    "            Pred_Max_Positions.append(j)\n",
    "#Pred_Max_Positions\n",
    "\n",
    "Test_Max_Positions=[]\n",
    "for i in range(72):\n",
    "    res=max(y_test[i])\n",
    "    #print(res)\n",
    "    for j in range(2):\n",
    "        if (res==y_test[i][j]):\n",
    "            result=j\n",
    "            Test_Max_Positions.append(j)\n",
    "#Test_Max_Positions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Test_Max_Positions,Pred_Max_Positions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM_CNN_3=confusion_matrix(Test_Max_Positions,Pred_Max_Positions)\n",
    "CM_CNN_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,threshold=roc_curve(Test_Max_Positions,Pred_Max_Positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2145f1e9898>]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4nHW99/H3d7JvzdKmW5LuC6RbChGQI4KI0oK07C1enAvP4Yj6HJSy6CmiWBFXllaPqAeXx0c92hZkqQJWZFFkT2m6b+madE2bNF2yJ7/nj0zbSZo002Qy98zk87quXszMfU/m8yOZTyb3717MOYeIiMQWn9cBREQk9FTuIiIxSOUuIhKDVO4iIjFI5S4iEoNU7iIiMUjlLiISg1TuIiIxSOUuIhKD4r164UGDBrlRo0Z59fIiIlFpxYoVB51zud2t51m5jxo1ipKSEq9eXkQkKpnZzmDW02YZEZEYpHIXEYlBKncRkRikchcRiUEqdxGRGNRtuZvZr8zsgJmt7WK5mdmPzKzMzFab2XmhjykiImcjmE/uvwZmnGH5TGC8/98dwE97H0tERHqj2/3cnXP/MLNRZ1hlNvAb13a9vnfMLMvMhjnn9oYoYzslO6p4a+shCnJSKMhOJT87lcEZSfh81hcvJyISlUJxEFMeUB5wv8L/2GnlbmZ30PbpnhEjRvToxVbsrObxlze3eywx3kd+Vgr5OakUZKeQn516svwLclLJTk3ATOUvIv1HKMq9s9bs9KrbzrkngScBiouLe3Rl7s9dOpbbLh7F7sN1lFfVUl5dR0V1LRVVdZRX17Km4jDVtU3tnpOWGHey8PP9hZ+ffaL8U8hITuhJFBGRiBWKcq8ACgLu5wN7QvB1u5ScEMfY3HTG5qZ3uvxYQzMV1bWUV534BVBLRXXb7Xe2VXGsobnd+lmpCf5NPCkUnPj0n5N68rHkhLi+HI6ISMiFotyXAXea2WLgQqCmr7a3Bys9KZ5zhg7gnKEDTlvmnONwbVO7wi/3/yLYtP8or2w8QGNza7vn5GYkUeAv/lOf+NvKf1hWMglx2qNURCJLt+VuZn8ALgMGmVkF8A0gAcA59zPgReAqoAyoBf6tr8KGgpmRnZZIdloiU/OzTlve2uo4eKzhZOGXV/l/CVTX8sGuav68ei8trae2KPkMhmWmBHzqD/gLICeFIRnJmuwVkbCztp1cwq+4uNhF41khm1ta2VtTf7LwKwK2+5dX1bH/aD2B/0sT43zkZbeVf+BE74lfAAPTEjXZKyJBM7MVzrni7tbz7JS/0So+zuf/VJ7Khxl42vKG5hZ2V9e1K/wTvwSW79lH1fHGduunJsad3NSTf3LTz6nJ38wUTfaKyNlTuYdYUnwcY3LTGdPFZO/xhubTtvVXVLd9+n9vexVHO0z2DkiOP7m559TePqf28U9J1GSviJxO5R5maUnxTByawcShGactc85RU9d0WvmXV9dSVnmM1zYdoKHDZO+g9MSTu3d2nPQdnpVCYrwme0X6I5V7BDEzslITyUpNZHJe5mnLnXNUHms4+Wk/8JfAqvLDvLRmL80dJnuHDkgmPzuV/JzAvXzadvUcOiCZOE32isQklXsUMTMGZyQzOCOZ80dmn7a8pdWx70h9W+F3OMDr7a2HePbI7naTvQlxxvCsjtv7T+31Myhdk70i0UrlHkPifEZeVgp5WSlcNKbzyd49h+vbTfSe+CXwtw37OXis/WRvcoKvbZNPF/v4Z6ZqslckUqnc+5Gk+DhGD0pj9KC0TpfXNp6a7O243b9kZzVH69tP9mYkx7cr/1Pn9Wmb9E1N1I+XiFf07pOTUhPjmTAkgwlDTp/sBaipa/IXf8AuntV1bD94nH9sqaS+qf1k78C0RPI7nMfnxCagvOwUkuK1p49IX1G5S9AyUxLIzMvscrL34LHGdqd1OPFLYO3uGv66bh9NLac2+JvBkIzkdoWfH7DL57DMFE32ivSCyl1CwszIzUgiNyOJ80Z0Ptm7/8Rkb4cDvN7Zdoi9R9of2RvvM4ZlJbeVfSf7+OdmJGmyV+QMVO4SFnG+tj1zhmelcGEnyxubW9lbU3faRG9FdS2vbDzAwWMN7dZPiveddkqHwEnfLJ3DX/o5lbtEhMR4HyMHpjFyYOeTvXWNLaf27T9R/v5fBKXlh6mpa38O//Sk+Pa7dwZM9OZnp5KepB99iW36CZeokJIYx/ghGYw/w2RvRcDpHE5s99956Dj/3HKQuqaWdutnpyacOovniU0+/l8GeVk6h79EP5W7xITMlAQyUzKZNLzzyd5Dxxs7PafP+r1HeHn9fhpb2u/pM2RAUofdPE8d4DUsM5l4ncNfIpzKXWKemTEoPYlB6UkUFXR+Dv/9R+tPncQtYLv/+zuqWbZqDwFndSDOZwzLTD5tc48u2C6RROUu/Z7PZwzLbNv98oLROactb2ppZe/h+oCJ3lObfV7fXEnl0faTvbpgu0QClbtINxLifIwYmMqIgamdLq9vajnt4i0njvJdXXGYw91csP3E5p6PjBtEmiZ6JUT0kyTSS8kJcYwbnM64wZ2fw/9ofVO7I3oDD/B6a+shahvbJnun5Wfy9Bcu1jV5JSRU7iJ9LCM5gcLhCRQO7/yC7dW1TSxft4/7n1nDf7+yhXs+OdGDlBJr9BFBxENmRk5aIrdcMIIbzsvnx6+VsWJnldexJAao3EUixIJZhQzPSmHeklKOdbjcosjZUrmLRIiM5AQWzSlid3UdC5at8zqORDmVu0gEKR6Vw39+bBxPr6jgxTV7vY4jUUzlLhJhvvTx8UzNz+Srz65hX02913EkSqncRSJMQpyPRXOKaGhq5ctPr6I18PBYkSCp3EUi0JjcdL72qXN5Y8tBfv3WDq/jSBRSuYtEqE9fMIIrzh3M9/6ykU37jnodR6KMyl0kQpkZ37thKgOS47lr8Uoamlu6f5KIn8pdJIINSk/iBzdOZeO+ozy6fJPXcSSKqNxFItzl5wzh1otG8PM3tvNm2UGv40iUCKrczWyGmW0yszIzm9/J8hFm9pqZrTSz1WZ2VeijivRfD1xVyJjcNO5duoqaDmeZFOlMt+VuZnHAE8BMoBC4xcwKO6z2NWCpc246MBf4SaiDivRnKYlx/HDOdA4ea+Crz63BOe0eKWcWzCf3C4Ay59w251wjsBiY3WEdB5w45V0msCd0EUUEYEp+Jnd/YgIvrN7Lsyt3ex1HIlww5Z4HlAfcr/A/FmgBcKuZVQAvAl8MSToRaefzl47lQ6OyefD5dZRX1XodRyJYMOXe2fXAOv5NeAvwa+dcPnAV8FszO+1rm9kdZlZiZiWVlZVnn1akn4vzGY/fXATAPUtLadHRq9KFYMq9AigIuJ/P6ZtdbgeWAjjn3gaSgUEdv5Bz7knnXLFzrjg3N7dniUX6uYKcVB6aPYn3d1Tzs79v9TqORKhgyv19YLyZjTazRNomTJd1WGcX8HEAMzuXtnLXR3ORPnLd9DyunjqMhS9vZk1FjddxJAJ1W+7OuWbgTmA5sIG2vWLWmdlDZjbLv9q9wGfNbBXwB+AzTtP5In3GzPjOtVPIzUjiriUrqWvU0avSnnnVwcXFxa6kpMST1xaJFW+VHeTTv3iXWy8awcPXTvE6joSBma1wzhV3t56OUBWJYhePG8RnLxnN797Zxasb93sdRyKIyl0kyt135UTOGZrBV55ezcFjDV7HkQihcheJcknxcfxw7nSO1Dcz/4+rdfSqACp3kZgwcWgG82ecw982HOD37+3yOo5EAJW7SIz4zMWjuGT8IL715/VsrTzmdRzxmMpdJEb4fMajN00jOSGOu5eU0tTS6nUk8ZDKXSSGDBmQzHeum8Lqihp+9MoWr+OIh1TuIjHmqinDuPH8fJ54rYySHVVexxGPqNxFYtCCWZPIz05l3pJSjtbr4h79kcpdJAalJ8WzcM409hyuY8Gy9V7HEQ+o3EVi1Pkjc7jzY+P44wcVvLB6r9dxJMxU7iIx7IsfH8+0/Ey++uwa9tXUex1HwkjlLhLDEuJ8LJxTRGNzK/c9tYpWXdyj31C5i8S4MbnpPHhNIf8sO8iv3tzudRwJE5W7SD8w90MFXHHuEH7wl01s3HfE6zgSBip3kX7AzPj+DVMYkJLAvMWl1Dfp4h6xTuUu0k8MTE/ikRunsnHfUR5dvsnrONLHVO4i/cjHzhnMv140kl/8cztvlh30Oo70IZW7SD/z1avOZWxuGvcuXcXh2kav40gfUbmL9DMpiW0X9zh4rIGvPrtGF/eIUSp3kX5ocl4m93xyAi+u2cczH+z2Oo70AZW7SD/1uY+O5YJROXxj2TrKq2q9jiMhpnIX6afifMbjc6ZhwN1LSmnR0asxReUu0o/lZ6fyrWsnU7Kzmp++XuZ1HAkhlbtIPze7aDjXTBvOor9tYVX5Ya/jSIio3EX6OTPj4dmTyc1I4u4lpdQ2NnsdSUJA5S4iZKYm8NjN09h+6DjffmGD13EkBFTuIgLAxWMH8dlLxvC/7+7ilQ37vY4jvaRyF5GT7v3kBM4dNoCvPL2ayqMNXseRXlC5i8hJSfFx/HBuEUcbmvmvP67W0atRTOUuIu1MGJLB/TPP4dWNB/jfd3d5HUd6KKhyN7MZZrbJzMrMbH4X69xsZuvNbJ2Z/T60MUUknG778CguGT+Ih19Yz9bKY17HkR7ottzNLA54ApgJFAK3mFlhh3XGA/cD/+KcmwTM64OsIhImPp/x6E3TSEmIY97iUppaWr2OJGcpmE/uFwBlzrltzrlGYDEwu8M6nwWecM5VAzjnDoQ2poiE25AByXz3+ims2V3Dor9t9jqOnKVgyj0PKA+4X+F/LNAEYIKZvWlm75jZjM6+kJndYWYlZlZSWVnZs8QiEjYzJg/j5uJ8fvL6Vt7bXuV1HDkLwZS7dfJYxyn0eGA8cBlwC/ALM8s67UnOPemcK3bOFefm5p5tVhHxwIPXTKIgO5W7l5RypL7J6zgSpGDKvQIoCLifD+zpZJ3nnXNNzrntwCbayl5Eolx6UjwL5xSxt6aOBcvWeR1HghRMub8PjDez0WaWCMwFlnVY5zngYwBmNoi2zTTbQhlURLxz/shs7rx8PM98sJs/r+742U4iUbfl7pxrBu4ElgMbgKXOuXVm9pCZzfKvthw4ZGbrgdeALzvnDvVVaBEJvy9ePo6igiweeHYte2vqvI4j3TCvjkArLi52JSUlnry2iPTM9oPHufpHb1BUkMXvbr8Qn6+zKTnpS2a2wjlX3N16OkJVRII2elAaD36qkLe2HuJXb273Oo6cgcpdRM7KnA8V8InCIfzgL5vYsPeI13GkCyp3ETkrZsb3rp9CZmoC8xaXUt/U4nUk6YTKXUTO2sD0JB65cSqb9h/lkeWbvI4jnVC5i0iPXDZxMLd9eCS//Od23tiiI84jjcpdRHps/sxzGTc4nfueWkX18Uav40gAlbuI9FhKYhyL5hRRdbyRrz67Rhf3iCAqdxHplcl5mdzziYm8tHYff/xgt9dxxE/lLiK9dsdHx3Dh6By+8fxadh2q9TqOoHIXkRCI8xmPzynC5zPuXlpKsy7u4TmVu4iERF5WCg9fO5kVO6v56etbvY7T76ncRSRkZhflMWvacBa9soXS8sNex+nXVO4iElLfunYyQzKSuHtJKbWNzV7H6bdU7iISUpkpCTx2cxE7Dh3n4Rc2eB2n31K5i0jIfXjsQO746Bh+/+4uXl6/3+s4/ZLKXUT6xD2fmEDhsAH81x9Xc+Bovddx+h2Vu4j0iaT4OH44t4jjDc3819OrdfRqmKncRaTPjB+Swf0zz+G1TZX87t1dXsfpV1TuItKnbrt4FJdOyOXbL6yn7MAxr+P0Gyp3EelTZsYjN04lJSGOeUtW0tiso1fDQeUuIn1u8IBkvnv9VNbuPsKiv232Ok6/oHIXkbCYMXkoc4oL+Onft/Le9iqv48Q8lbuIhM2D1xQyIieVu5eUcqS+yes4MU3lLiJhk5YUz8I5Rew7Us+C59d5HSemqdxFJKzOG5HNFy8fxzMrd/OnVXu8jhOzVO4iEnZ3fmwcRQVZPPDsGvYcrvM6TkxSuYtI2MXH+Vg0p4jmVse9S1fR2qqjV0NN5S4inhg1KI1vXFPI29sO8ct/bvc6TsxRuYuIZ24uLuDKSUN4ZPkm1u854nWcmKJyFxHPmBnfvX4qmakJzFuykvqmFq8jxYygyt3MZpjZJjMrM7P5Z1jvRjNzZlYcuogiEsty0hJ59KZpbN5/jO//ZaPXcWJGt+VuZnHAE8BMoBC4xcwKO1kvA/gS8G6oQ4pIbLt0Qi6fuXgU//fNHfxjc6XXcWJCMJ/cLwDKnHPbnHONwGJgdifrfQv4AaCz8ovIWZs/8xzGD07nvqdWUX280es4US+Ycs8DygPuV/gfO8nMpgMFzrk/hzCbiPQjyQlxLJpbRHVtI/c/s0YX9+ilYMrdOnns5P91M/MBC4F7u/1CZneYWYmZlVRW6k8vEWlv0vBM7vvkRP6ybh9PrajwOk5UC6bcK4CCgPv5QOAxwxnAZOB1M9sBXAQs62xS1Tn3pHOu2DlXnJub2/PUIhKz/uOSMVw0JodvLlvHzkPHvY4TtYIp9/eB8WY22swSgbnAshMLnXM1zrlBzrlRzrlRwDvALOdcSZ8kFpGYFuczHru5CJ/PuHtJKc0turhHT3Rb7s65ZuBOYDmwAVjqnFtnZg+Z2ay+Digi/U9eVgoPXzuZD3Yd5ievb/U6TlSKD2Yl59yLwIsdHnuwi3Uv630sEenvZhfl8erGA/zwlS18dEIuRQVZXkeKKjpCVUQi1kOzJzN0QDLzFq/keEOz13GiispdRCJWZkoCj908jZ1VtTz8wnqv40QVlbuIRLSLxgzkcx8dyx/eK+ev6/Z5HSdqqNxFJOLd84kJFA4bwPxn1nDgqA6CD4bKXUQiXmK8jx/dUsTxhma+8vRqHb0aBJW7iESFcYMzeODqc3l9UyW/fWen13EinspdRKLGv140kksn5PLtFzZQduCo13EimspdRKKGmfHITVNJS4rnrsWlNDbr6NWuqNxFJKoMzkjmu9dPYd2eIyz822av40QslbuIRJ0rJw1l7ocK+Nnft/LutkNex4lIKncRiUpf/1QhI3NSuWfpKmrqmryOE3FU7iISldKS4lk4p4h9R+r5xvNrvY4TcVTuIhK1po/I5kuXj+e50j08X7rb6zgRReUuIlHtPz82lukjsvjac2vZfbjO6zgRQ+UuIlEtPs7HojlFtLY67l1aSmurjl4FlbuIxICRA9P4xqxJvLOtip+/sc3rOBFB5S4iMeGm8/OZMWkoj/51E+v21Hgdx3MqdxGJCWbGd66fQnZqIvMWl1Lf1OJ1JE+p3EUkZuSkJfLITdPYcuAY33tpo9dxPKVyF5GYcumEXD5z8Sh+/dYO/r650us4nlG5i0jMmT/zHCYMSee+p1ZRdbzR6zieULmLSMxJTohj0Zzp1NQ2cf8z/fPiHip3EYlJhcMHcN+VE1i+bj9PlVR4HSfsVO4iErP+4yNj+PCYgSz40zp2HjrudZywUrmLSMzy+YzHbp5GvM+Yt6SU5pb+c3EPlbuIxLThWSl8+7oprNx1mCde2+p1nLBRuYtIzLtm2nCum57Hj17dwge7qr2OExYqdxHpF745exJDByRz95JSjjc0ex2nz6ncRaRfGJCcwOM3T2NXVS3f+vN6r+P0OZW7iPQbF44ZyOcvHcvi98tZvm6f13H6lMpdRPqVu6+YwOS8Acz/42oOHKn3Ok6fCarczWyGmW0yszIzm9/J8nvMbL2ZrTazV8xsZOijioj0XmK8j0VzplPX1MKXn47do1e7LXcziwOeAGYChcAtZlbYYbWVQLFzbirwNPCDUAcVEQmVcYPTeeCqc/n75kp+8/ZOr+P0iWA+uV8AlDnntjnnGoHFwOzAFZxzrznnav133wHyQxtTRCS0br1oJJdNzOU7L25gy/6jXscJuWDKPQ8oD7hf4X+sK7cDL3W2wMzuMLMSMyuprOy/p+IUEe+ZGT+4cSppSfHctbiUxubYOno1mHK3Th7rdCOVmd0KFAOPdLbcOfekc67YOVecm5sbfEoRkT4wOCOZ798wlfV7j/D4y5u9jhNSwZR7BVAQcD8f2NNxJTO7AngAmOWcawhNPBGRvvWJwiHccsEI/ucfW3l76yGv44RMMOX+PjDezEabWSIwF1gWuIKZTQf+h7ZiPxD6mCIifefrnzqXUQPTuHdpKTV1TV7HCYluy9051wzcCSwHNgBLnXPrzOwhM5vlX+0RIB14ysxKzWxZF19ORCTipCbGs3BOEfuPNvDg82u9jhMS8cGs5Jx7EXixw2MPBty+IsS5RETCqqggi7s+Pp7HX97M5ecMZnbRmfYbiXw6QlVExO//XDaW80dm87Xn1rL7cJ3XcXpF5S4i4hcf52PhzUW0tjruWVJKS2v0Hr2qchcRCTBiYCoLZk3i3e1V/PyNbV7H6TGVu4hIBzeen8/MyUN57K+bWLu7xus4PaJyFxHpwMz4znVTyElLZN6SUuqbWryOdNZU7iIinchOS+TRm6ZRduAY33tpo9dxzprKXUSkC5eMz+Xf/2U0v35rB69viq7jM1XuIiJn8JUZE5kwJJ0vP72aQ8ei58wqKncRkTNITohj0Zzp1NQ2cf8za6Lm4h4qdxGRbhQOH8CXr5zIX9fvZ2lJefdPiAAqdxGRINz+kdFcPHYg3/zTenYcPO51nG6p3EVEguDzGY/dPI14nzFvSSlNLZF9cQ+Vu4hIkIZlpvCd66dQWn6YH79a5nWcM1K5i4ichU9NHc710/P48WtlrNhZ7XWcLqncRUTO0oLZkxg6IJl7lpZyrKHZ6zidUrmLiJylAckJLJxTRHlVLd/603qv43RK5S4i0gMXjM7hC5eNZUlJOX9Zu8/rOKdRuYuI9NBdH5/AlLxM5j+zmv1H6r2O047KXUSkhxLjfSycU0R9Uwv3PbWK1gi6uIfKXUSkF8YNTueBqwt5Y8tBfvP2Dq/jnKRyFxHppVsvHMHl5wzmuy9tZPP+o17HAVTuIiK9ZmZ8/4appCfFc9fiUhqavb+4h8pdRCQEcjOS+P4NU9mw9wiP/3Wz13FU7iIioXJF4RA+feEInnxjG29tPehpFpW7iEgIfe3qcxk9MI17l66iprbJsxwqdxGREEpNjGfR3CIqjzbw9efXepZD5S4iEmJT87OYd8V4lq3aw3Mrd3uSQeUuItIHvnDZOIpHZvP159ZSUV0b9tdXuYuI9IE4n7FwThEOuGfpKlrCfPSqyl1EpI8U5KSyYNYk3ttexZP/2BbW1w6q3M1shpltMrMyM5vfyfIkM1viX/6umY0KdVARkWh0w3l5XD1lGI+/vIm1u2vC9rrdlruZxQFPADOBQuAWMyvssNrtQLVzbhywEPh+qIOKiEQjM+Pb100mJy2RuxavpK4xPEevBvPJ/QKgzDm3zTnXCCwGZndYZzbw//y3nwY+bmYWupgiItErKzWRx24qYmvlcb770oawvGYw5Z4HlAfcr/A/1uk6zrlmoAYYGIqAIiKx4CPjB3H7R0bzm7d38trGA33+evFBrNPZJ/CO077BrIOZ3QHcATBixIggXlpEJHZ8+cqJbD94nLSkYKq3d4L55F4BFATczwf2dLWOmcUDmUBVxy/knHvSOVfsnCvOzc3tWWIRkSiVnBDHrz7zIS4YndPnrxVMub8PjDez0WaWCMwFlnVYZxlwm//2jcCrzrnIuSSJiEg/0+3fBs65ZjO7E1gOxAG/cs6tM7OHgBLn3DLgl8BvzayMtk/sc/sytIiInFlQG36ccy8CL3Z47MGA2/XATaGNJiIiPaUjVEVEYpDKXUQkBqncRURikMpdRCQGqdxFRGKQebU7uplVAju7WDwI8PbqsqGl8UQ2jSeyxdp4oHdjGumc6/YoUM/K/UzMrMQ5V+x1jlDReCKbxhPZYm08EJ4xabOMiEgMUrmLiMSgSC33J70OEGIaT2TTeCJbrI0HwjCmiNzmLiIivROpn9xFRKQXwlruQVxoe6GZlfr/bTazwwHLbjOzLf5/t3V8rhd6OZ6WgGUdT6HsmSDGNMLMXjOzlWa22syuClh2v/95m8zsyvAm71xPx2Nmo8ysLuB79LPwpz9dEOMZaWav+MfyupnlByyLxvfQmcYTce8hM/uVmR0ws7VdLDcz+5F/vKvN7LyAZaH9/jjnwvKPttMFbwXGAInAKqDwDOt/kbbTCwPkANv8/832384OV/ZQj8d//5iX+Xs6Jtq2FX7Bf7sQ2BFwexWQBIz2f524KB7PKGCt19+THoznKeA2/+3Lgd/6b0fle6ir8fjvR+J76KPAeV397ABXAS/RdvW6i4B3++r7E85P7sFcaDvQLcAf/LevBF52zlU556qBl4EZfZq2e70ZT6QKZkwOGOC/ncmpq3LNBhY75xqcc9uBMv/X81JvxhOJghlPIfCK//ZrAcuj9T3U1XgiknPuH3RyFboAs4HfuDbvAFlmNow++P6Es9yDudA20PanGG2f/l492+eGUW/GA5BsZiVm9o6ZXdt3Mc9KMGNaANxqZhW0neP/i2fx3HDrzXgARvs31/zdzC7p06TBCWY8q4Ab/LevAzLMbGCQzw233owHIvM91J2uxhzy7084yz2oi2j7zQWeds619OC54dKb8QCMcG1HqH0aWGRmY0MdsAeCGdMtwK+dc/m0/Yn5WzPzBfnccOvNePbS9j2aDtwD/N7MBuCtYMZzH3Cpma0ELgV2A81BPjfcejMeiMz3UHe6GnPIvz/hLPdgLrR9wlzab8I4m+eGS2/Gg3Nuj/+/24DXgemhj3jWghnT7cBSAOfc20AybefJiNbvUafj8W9eOuR/fAVt24Yn9HniM+t2PM65Pc656/2/lB7wP1YTzHM90JvxROp7qDtdjTn0358wTjTE0zZJMJpTkyeTOllvIrAD/z74AZMN22mbaMj2384JV/Y+GE82kOS/PQjYwhkmYyNpTLRNBn3Gf/tc/w+gAZNoP6G6De8nVHszntwT+Wmb8NsdDT9z/p8nn//2t4GH/Lej8j10hvFE5HvIn2cUXU+oXk37CdX3+uo8ZkbvAAAAyElEQVT7E+5BXwVspu1T0AP+xx4CZgWsswD4XifP/XfaJunKgH/z+hvYm/EAFwNr/D/Ma4DbvR5LsGOibYLrTX/2UuCTAc99wP+8TcBMr8fSm/HQtp13nf/xD4BrvB5LkOO50V90m4FfnChA/7Koew91NZ5IfQ/R9hf6XqCJtk/jtwOfBz7vX27AE/7xrgGK++r7oyNURURikI5QFRGJQSp3EZEYpHIXEYlBKncRkRikchcRiUEqdxGRGKRyFxGJQSp3EZEY9P8B3FXLASExkA8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Test_Max_Positions,Pred_Max_Positions)\n",
    "plt.plot(precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
